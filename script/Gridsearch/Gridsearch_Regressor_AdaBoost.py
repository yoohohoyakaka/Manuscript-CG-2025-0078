import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
from sklearn.ensemble import AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# 1ï¸âƒ£ åŠ è½½æ•°æ®
file_path = "dataset_0304.xlsx"  # ä¿®æ”¹ä¸ºä½ çš„è·¯å¾„
df = pd.read_excel(file_path)

# 2ï¸âƒ£ ç‰¹å¾ä¸ç›®æ ‡
features = ["TDEP", "VELP", "VELS"]  # å¯æ ¹æ®éœ€è¦è°ƒæ•´
target = "Sh"  # è¿ç»­å€¼æ ‡ç­¾

X = df[features]
y = df[target]

# 3ï¸âƒ£ åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 4ï¸âƒ£ å®šä¹‰åŸºç¡€æ¨¡å‹
base_estimator = DecisionTreeRegressor(random_state=42)

adaboost = AdaBoostRegressor(
    estimator=base_estimator,
    random_state=42
)

# 5ï¸âƒ£ æ„é€ å‚æ•°æœç´¢ç©ºé—´
param_grid = {
    'n_estimators': [50, 100, 200, 500, 1000],
    'learning_rate': [0.1, 0.3, 0.5, 1.0],
    'estimator__max_depth': [2, 3, 4, 5]
}

# 6ï¸âƒ£ æ„é€  GridSearchCV
cv = KFold(n_splits=5, shuffle=True, random_state=42)

grid_search = GridSearchCV(
    estimator=adaboost,
    param_grid=param_grid,
    cv=cv,
    scoring='r2',  # å›å½’å¸¸ç”¨æŒ‡æ ‡
    n_jobs=-1,
    verbose=1
)

# 7ï¸âƒ£ æ‰§è¡Œæœç´¢
grid_search.fit(X_train, y_train)

# 8ï¸âƒ£ æ‰“å°æœ€ä¼˜å‚æ•°ä¸å¾—åˆ†
print("âœ… Best Parameters:", grid_search.best_params_)
print(f"âœ… Best CV RÂ² Score: {grid_search.best_score_:.4f}")

# 9ï¸âƒ£ ä½¿ç”¨æœ€ä¼˜æ¨¡å‹é¢„æµ‹
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

# ğŸ”Ÿ æµ‹è¯•é›†è¯„ä¼°æŒ‡æ ‡
print("\nğŸ“Š Test Set Evaluation:")
print(f"RÂ² Score:  {r2_score(y_test, y_pred):.4f}")
print(f"MAE:       {mean_absolute_error(y_test, y_pred):.4f}")
print(f"RMSE:      {mean_squared_error(y_test, y_pred) ** 0.5:.4f}")

